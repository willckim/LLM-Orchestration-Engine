# ============================================
# LLM Orchestration Engine - Backend Environment
# Copy this to .env and fill in your API keys
# ============================================

# --------------------------------------------
# Application Settings
# --------------------------------------------
ENVIRONMENT=development
DEBUG=true
API_KEYS=dev-key-123,test-key-456

# --------------------------------------------
# OpenAI (ChatGPT)
# Get key at: https://platform.openai.com/api-keys
# Models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# --------------------------------------------
OPENAI_API_KEY=sk-your-openai-key-here

# --------------------------------------------
# Anthropic (Claude)
# Get key at: https://console.anthropic.com/settings/keys
# Models: claude-3-5-sonnet, claude-3-5-haiku, claude-3-opus
# --------------------------------------------
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# --------------------------------------------
# Google Gemini
# Get key at: https://aistudio.google.com/app/apikey
# Models: gemini-1.5-pro, gemini-1.5-flash, gemini-2.0-flash-exp
# --------------------------------------------
GEMINI_API_KEY=your-gemini-api-key-here

# --------------------------------------------
# Azure OpenAI
# Get from Azure Portal: https://portal.azure.com
# --------------------------------------------
AZURE_API_KEY=your-azure-openai-key-here
AZURE_API_BASE=https://your-resource-name.openai.azure.com
AZURE_API_VERSION=2024-02-15-preview
# Deployment names (set when deploying models in Azure Portal)
AZURE_GPT4O_DEPLOYMENT=gpt-4o
AZURE_GPT4O_MINI_DEPLOYMENT=gpt-4o-mini

# --------------------------------------------
# AWS Bedrock
# Configure AWS credentials (or use IAM roles in production)
# Models: anthropic.claude-3-sonnet, meta.llama3-70b-instruct
# --------------------------------------------
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_REGION=us-east-1

# --------------------------------------------
# Local ONNX Models (Free, runs locally)
# Good for: sentiment analysis, text classification
# --------------------------------------------
ENABLE_LOCAL_MODELS=false
LOCAL_MODEL_PATH=./models

# --------------------------------------------
# Storage Settings
# --------------------------------------------
USE_LOCAL_STORAGE=true
LOCAL_STORAGE_PATH=./data/logs.json

# For production with DynamoDB:
# USE_LOCAL_STORAGE=false
# DYNAMODB_TABLE_NAME=llm-orchestration-logs
# S3_BUCKET_NAME=llm-orchestration-outputs

# --------------------------------------------
# Routing Defaults
# --------------------------------------------
DEFAULT_PREFERENCE=balanced
MAX_RETRIES=3
TIMEOUT_SECONDS=30

# --------------------------------------------
# Metrics & Observability
# --------------------------------------------
ENABLE_METRICS=true
METRICS_RETENTION_DAYS=30
